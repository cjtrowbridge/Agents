{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Notebook\n",
    "This notebook demonstrates an agent workflow using autogen and models hosted on Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: ag2[openai] in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: autogen-ext[ollama] in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: jupytext in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.2)\n",
      "Requirement already satisfied: markdownify in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.46.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (4.9.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.0.8)\n",
      "Requirement already satisfied: diskcache in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (7.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from ag2[openai]) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (2.11.7)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (1.1.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.9.0)\n",
      "Requirement already satisfied: openai>=1.87.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (1.93.0)\n",
      "Requirement already satisfied: autogen-core==0.6.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.6.2)\n",
      "Requirement already satisfied: ollama>=0.4.7 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.5.1)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (0.55b1)\n",
      "Requirement already satisfied: pillow>=11.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (11.2.1)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (5.29.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (4.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (8.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (0.4.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (5.10.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (6.0.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (4.13.4)\n",
      "Requirement already satisfied: six<2,>=1.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (1.16.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2[openai]) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2[openai]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2[openai]) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=1.0->jupytext) (0.1.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.87.0->ag2[openai]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.87.0->ag2[openai]) (0.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken->ag2[openai]) (2024.11.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from docker->ag2[openai]) (310)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker->ag2[openai]) (2.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (3.23.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U autogen ag2[openai] autogen-ext[ollama] jupytext markdownify accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "# local fallback client if library missing or openai unavailable\n",
    "try:\n",
    "    from autogen import OpenAIChatCompletionClient as _OAIClient\n",
    "    import openai\n",
    "    OpenAIChatCompletionClient = _OAIClient\n",
    "except Exception:\n",
    "    class OpenAIChatCompletionClient:\n",
    "        def __init__(self, model, base_url=None, api_key=None):\n",
    "            self.model = model\n",
    "            self.base_url = base_url\n",
    "            self.api_key = api_key\n",
    "        def chat(self, messages, temperature=0):\n",
    "            raise NotImplementedError('OpenAIChatCompletionClient is unavailable')\n",
    "import pathlib, datetime, uuid, subprocess, shlex, markdownify\n",
    "\n",
    "REPO_ROOT = pathlib.Path.cwd()\n",
    "LOG_DIR = REPO_ROOT / 'agent_logs'\n",
    "LOG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BASE_URL = 'http://docker-ai:11434/v1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen14_client = OpenAIChatCompletionClient(\n",
    "    model='Qwen2.5-14B-Instruct-1M-Q8_0:latest',\n",
    "    base_url=BASE_URL,\n",
    "    api_key='ollama')\n",
    "\n",
    "qwen32_client = OpenAIChatCompletionClient(\n",
    "    model='Qwen3-32B-Q5_0:latest',\n",
    "    base_url=BASE_URL,\n",
    "    api_key='ollama')\n",
    "\n",
    "devstral_client = OpenAIChatCompletionClient(\n",
    "    model='devstral:24b',\n",
    "    base_url=BASE_URL,\n",
    "    api_key='ollama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_markdown(task_id, role, content):\n",
    "    ts = datetime.datetime.utcnow().isoformat()\n",
    "    fn = LOG_DIR / f\"{task_id}.md\"\n",
    "    if not fn.exists():\n",
    "        with open(fn, 'w') as f:\n",
    "            f.write(f'---\\nid: {task_id}\\ncreated: {ts}\\n---\\n\\n')\n",
    "    with open(fn, 'a') as f:\n",
    "        f.write(f'### {ts} — {role}\\n\\n{markdownify.markdownify(content)}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shell(cmd: str) -> str:\n",
    "    out = subprocess.check_output(shlex.split(cmd), text=True, timeout=900, stderr=subprocess.STDOUT)\n",
    "    return f'```shell\\n$ {cmd}\\n{out}\\n```'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m group = GroupChat(agents=agents, max_round=\u001b[32m30\u001b[39m)\n\u001b[32m     26\u001b[39m manager = GroupChatManager(groupchat=group)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m proxy = \u001b[43mUserProxyAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNEVER\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\user_proxy_agent.py:94\u001b[39m, in \u001b[36mUserProxyAgent.__init__\u001b[39m\u001b[34m(self, name, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, default_auto_reply, llm_config, system_message, description, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     37\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     **kwargs: Any,\n\u001b[32m     48\u001b[39m ):\n\u001b[32m     49\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Args:\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    name (str): name of the agent.\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m    is_termination_msg (function): a function that takes a message in the form of a dictionary\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m \u001b[33;03m        [ConversableAgent](https://docs.ag2.ai/latest/docs/api-reference/autogen/ConversableAgent).\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_termination_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_termination_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_execution_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_execution_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mDEFAULT_USER_PROXY_AGENT_DESCRIPTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m    111\u001b[39m         log_new_agent(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlocals\u001b[39m())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:348\u001b[39m, in \u001b[36mConversableAgent.__init__\u001b[39m\u001b[34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply, description, chat_messages, silent, context_variables, functions, update_agent_state_before_reply, handoffs)\u001b[39m\n\u001b[32m    346\u001b[39m use_docker = \u001b[38;5;28mself\u001b[39m._code_execution_config.get(\u001b[33m\"\u001b[39m\u001b[33muse_docker\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    347\u001b[39m use_docker = decide_use_docker(use_docker)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[43mcheck_can_use_docker_or_throw\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_docker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28mself\u001b[39m._code_execution_config[\u001b[33m\"\u001b[39m\u001b[33muse_docker\u001b[39m\u001b[33m\"\u001b[39m] = use_docker\n\u001b[32m    350\u001b[39m \u001b[38;5;28mself\u001b[39m.register_reply([Agent, \u001b[38;5;28;01mNone\u001b[39;00m], ConversableAgent.generate_code_execution_reply)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\code_utils.py:249\u001b[39m, in \u001b[36mcheck_can_use_docker_or_throw\u001b[39m\u001b[34m(use_docker)\u001b[39m\n\u001b[32m    247\u001b[39m docker_installed_and_running = is_docker_running()\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inside_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m docker_installed_and_running:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    250\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode execution is set to be run in docker (default behaviour) but docker is not running.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe options available are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    252\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m- Make sure docker is running (advised approach for code execution)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m- Set \u001b[39m\u001b[33m\"\u001b[39m\u001b[33muse_docker\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: False in code_execution_config\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m- Set AUTOGEN_USE_DOCKER to \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m0/False/no\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m in your environment variables\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    255\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables"
     ]
    }
   ],
   "source": [
    "planner = AssistantAgent(\n",
    "    name='planner',\n",
    "    llm_config={'config_list': [{ 'model': qwen14_client.model, 'base_url': qwen14_client.base_url, 'api_key': qwen14_client.api_key }], 'temperature': 0.3},\n",
    "    system_message=(\"You are a project planner. Break the user's request into a YAML list of atomic tasks. Stop when each sub-task can be executed in one short Python call or shell command inside the current Jupyter kernel.\"),\n",
    ")\n",
    "\n",
    "worker = AssistantAgent(\n",
    "    name='worker',\n",
    "    llm_config={'config_list': [{ 'model': qwen32_client.model, 'base_url': qwen32_client.base_url, 'api_key': qwen32_client.api_key }], 'temperature': 0},\n",
    "    system_message='Execute the given atomic task and return result.')\n",
    "worker.register_function({'run_shell': run_shell})\n",
    "\n",
    "coder = AssistantAgent(\n",
    "    name='coder',\n",
    "    llm_config={'config_list': [{ 'model': devstral_client.model, 'base_url': devstral_client.base_url, 'api_key': devstral_client.api_key }], 'temperature': 0},\n",
    "    system_message='You are a senior software engineer. Write, refactor, and debug code snippets as requested.')\n",
    "\n",
    "reviewer = AssistantAgent(\n",
    "    name='reviewer',\n",
    "    llm_config={'config_list': [{ 'model': qwen14_client.model, 'base_url': qwen14_client.base_url, 'api_key': qwen14_client.api_key }], 'temperature': 0},\n",
    "    system_message=(\"Evaluate the worker or coder output against the task description. If incorrect, respond with REVISE and instructions; otherwise APPROVED.\"),\n",
    ")\n",
    "\n",
    "agents = [planner, worker, coder, reviewer]\n",
    "group = GroupChat(agents=agents, max_round=30)\n",
    "manager = GroupChatManager(groupchat=group)\n",
    "proxy = UserProxyAgent(name='user', human_input_mode='NEVER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(prompt: str):\n",
    "    task_id = uuid.uuid4().hex[:8]\n",
    "    log_markdown(task_id, 'USER', prompt)\n",
    "    proxy.initiate_chat(manager, prompt=prompt)\n",
    "    for m in group.chat_history:\n",
    "        log_markdown(task_id, m['role'], m['content'])\n",
    "    return LOG_DIR / f'{task_id}.md'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_agent('Generate Python code to scrape example.com daily and store results in SQLite …')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git auto-commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add agent_logs/*.md && (git diff --cached --quiet || git commit -m 'agent run') && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep -E '(autogen|transformers|ollama)'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
