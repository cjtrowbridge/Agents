{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Agent Notebook\n",
                "This notebook demonstrates an agent workflow using autogen and models hosted on Ollama."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: autogen in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.5)\n",
                        "Requirement already satisfied: autogen-ext[ollama] in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.2)\n",
                        "Requirement already satisfied: jupytext in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.2)\n",
                        "Requirement already satisfied: markdownify in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
                        "Requirement already satisfied: accelerate in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.1)\n",
                        "Requirement already satisfied: bitsandbytes in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.46.1)\n",
                        "Requirement already satisfied: ag2==0.9.5 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen) (0.9.5)\n",
                        "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (4.9.0)\n",
                        "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (0.0.8)\n",
                        "Requirement already satisfied: diskcache in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (5.6.3)\n",
                        "Requirement already satisfied: docker in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (7.1.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.28.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (0.28.1)\n",
                        "Requirement already satisfied: packaging in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from ag2==0.9.5->autogen) (25.0)\n",
                        "Requirement already satisfied: pydantic<3,>=2.6.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (2.11.7)\n",
                        "Requirement already satisfied: python-dotenv in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (1.1.1)\n",
                        "Requirement already satisfied: termcolor in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (3.1.0)\n",
                        "Requirement already satisfied: tiktoken in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2==0.9.5->autogen) (0.9.0)\n",
                        "Requirement already satisfied: autogen-core==0.6.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.6.2)\n",
                        "Requirement already satisfied: ollama>=0.4.7 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.5.1)\n",
                        "Requirement already satisfied: jsonref~=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.1.0)\n",
                        "Requirement already satisfied: opentelemetry-api>=1.34.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.34.1)\n",
                        "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (0.55b1)\n",
                        "Requirement already satisfied: pillow>=11.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (11.2.1)\n",
                        "Requirement already satisfied: protobuf~=5.29.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (5.29.5)\n",
                        "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (4.14.0)\n",
                        "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (8.7.0)\n",
                        "Requirement already satisfied: markdown-it-py>=1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (3.0.0)\n",
                        "Requirement already satisfied: mdit-py-plugins in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (0.4.2)\n",
                        "Requirement already satisfied: nbformat in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (5.10.4)\n",
                        "Requirement already satisfied: pyyaml in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (6.0.1)\n",
                        "Requirement already satisfied: beautifulsoup4<5,>=4.9 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (4.13.4)\n",
                        "Requirement already satisfied: six<2,>=1.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (1.16.0)\n",
                        "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.2.6)\n",
                        "Requirement already satisfied: psutil in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (7.0.0)\n",
                        "Requirement already satisfied: torch>=2.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.7.1)\n",
                        "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.33.2)\n",
                        "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.5.3)\n",
                        "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.7)\n",
                        "Requirement already satisfied: filelock in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.5.1)\n",
                        "Requirement already satisfied: requests in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
                        "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
                        "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=1.0->jupytext) (0.1.2)\n",
                        "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken->ag2==0.9.5->autogen) (2024.11.6)\n",
                        "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
                        "Requirement already satisfied: networkx in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
                        "Requirement already satisfied: jinja2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
                        "Requirement already satisfied: setuptools in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
                        "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (2.21.1)\n",
                        "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (4.24.0)\n",
                        "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.8.1)\n",
                        "Requirement already satisfied: traitlets>=5.1 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.14.3)\n",
                        "Requirement already satisfied: idna>=2.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.5->autogen) (3.10)\n",
                        "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.5->autogen) (1.3.1)\n",
                        "Requirement already satisfied: certifi in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2==0.9.5->autogen) (2025.4.26)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2==0.9.5->autogen) (1.0.9)\n",
                        "Requirement already satisfied: h11>=0.16 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.5->autogen) (0.16.0)\n",
                        "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (25.3.0)\n",
                        "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (2025.4.1)\n",
                        "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.36.2)\n",
                        "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.25.1)\n",
                        "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.8)\n",
                        "Requirement already satisfied: pywin32>=300 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (310)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2==0.9.5->autogen) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2==0.9.5->autogen) (2.33.2)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2==0.9.5->autogen) (0.4.1)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
                        "Requirement already satisfied: colorama in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
                        "Requirement already satisfied: zipp>=3.20 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (3.23.0)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
                        "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
                    ]
                }
            ],
            "source": [
                "!pip install -U     autogen     autogen-ext[ollama]     jupytext markdownify     accelerate bitsandbytes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Imports and constants"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "from autogen import AssistantAgent, UserProxyAgent, GroupChat\n",
                "# local fallback client if library missing\n",
                "try:\n",
                "    from autogen import OpenAIChatCompletionClient\n",
                "except ImportError:\n",
                "    class OpenAIChatCompletionClient:\n",
                "        def __init__(self, model, base_url=None, api_key=None):\n",
                "            self.model = model\n",
                "            self.base_url = base_url\n",
                "            self.api_key = api_key\n",
                "        def chat(self, messages, temperature=0):\n",
                "            raise NotImplementedError('OpenAIChatCompletionClient is unavailable')\n",
                "import pathlib, datetime, uuid, subprocess, shlex, markdownify\n",
                "\n",
                "REPO_ROOT = pathlib.Path.cwd()\n",
                "LOG_DIR = REPO_ROOT / 'agent_logs'\n",
                "LOG_DIR.mkdir(exist_ok=True, parents=True)\n",
                "BASE_URL = 'http://docker-ai:11434/v1'\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Model clients"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "qwen14_client = OpenAIChatCompletionClient(\n",
                "    model='qwen2.5-14b-1m',\n",
                "    base_url=BASE_URL,\n",
                "    api_key='ollama')\n",
                "\n",
                "qwen32_client = OpenAIChatCompletionClient(\n",
                "    model='qwen3-32b-5k_s',\n",
                "    base_url=BASE_URL,\n",
                "    api_key='ollama')\n",
                "\n",
                "devstral_client = OpenAIChatCompletionClient(\n",
                "    model='devstral-24b-5k_s',\n",
                "    base_url=BASE_URL,\n",
                "    api_key='ollama')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Markdown logger"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def log_markdown(task_id, role, content):\n",
                "    ts = datetime.datetime.utcnow().isoformat()\n",
                "    fn = LOG_DIR / f\"{task_id}.md\"\n",
                "    if not fn.exists():\n",
                "        with open(fn, 'w') as f:\n",
                "            f.write(f'---\\nid: {task_id}\\ncreated: {ts}\\n---\\n\\n')\n",
                "    with open(fn, 'a') as f:\n",
                "        f.write(f'### {ts} — {role}\\n\\n{markdownify.markdownify(content)}\\n\\n')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Shell helper"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_shell(cmd: str) -> str:\n",
                "    out = subprocess.check_output(shlex.split(cmd), text=True, timeout=900, stderr=subprocess.STDOUT)\n",
                "    return f'```shell\\n$ {cmd}\\n{out}\\n```'\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Agent declarations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ValidationError",
                    "evalue": "2 validation errors for _LLMConfig\nconfig_list.0.openai.model\n  Field required [type=missing, input_value={'client': <__main__.Open...>, 'api_type': 'openai'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nconfig_list.0.openai.client\n  Extra inputs are not permitted [type=extra_forbidden, input_value=<__main__.OpenAIChatCompl...t at 0x00000225D9CA7230>, input_type=OpenAIChatCompletionClient]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m planner = \u001b[43mAssistantAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mplanner\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclient\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mqwen14_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a project planner. Break the user\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms request into a YAML list of atomic tasks. Stop when each sub-task can be executed in one short Python call or shell command inside the current Jupyter kernel.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m worker = AssistantAgent(\n\u001b[32m      8\u001b[39m     name=\u001b[33m'\u001b[39m\u001b[33mworker\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     llm_config={\u001b[33m'\u001b[39m\u001b[33mclient\u001b[39m\u001b[33m'\u001b[39m: qwen32_client, \u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m},\n\u001b[32m     10\u001b[39m     system_message=\u001b[33m'\u001b[39m\u001b[33mExecute the given atomic task and return result.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m worker.register_function(run_shell)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\assistant_agent.py:69\u001b[39m, in \u001b[36mAssistantAgent.__init__\u001b[39m\u001b[34m(self, name, system_message, llm_config, is_termination_msg, max_consecutive_auto_reply, human_input_mode, description, **kwargs)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     44\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     **kwargs: Any,\n\u001b[32m     52\u001b[39m ):\n\u001b[32m     53\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Args:\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m    name (str): agent name.\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    system_message (str): system message for the ChatCompletion inference.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[33;03m        [ConversableAgent](https://docs.ag2.ai/latest/docs/api-reference/autogen/ConversableAgent).\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_termination_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m     80\u001b[39m         log_new_agent(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlocals\u001b[39m())\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:262\u001b[39m, in \u001b[36mConversableAgent.__init__\u001b[39m\u001b[34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply, description, chat_messages, silent, context_variables, functions, update_agent_state_before_reply, handoffs)\u001b[39m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    257\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    258\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease implement __deepcopy__ method for each value class in llm_config to support deepcopy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    259\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Refer to the docs for more details: https://docs.ag2.ai/docs/user-guide/advanced-concepts/llm-configuration-deep-dive/#adding-http-client-in-llm_config-for-proxy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_config = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_llm_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28mself\u001b[39m._create_client(\u001b[38;5;28mself\u001b[39m.llm_config)\n\u001b[32m    264\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_name(name)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:498\u001b[39m, in \u001b[36mConversableAgent._validate_llm_config\u001b[39m\u001b[34m(cls, llm_config)\u001b[39m\n\u001b[32m    496\u001b[39m         llm_config = \u001b[38;5;28mcls\u001b[39m.DEFAULT_CONFIG\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m     llm_config = \u001b[43mLLMConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm_config, LLMConfig):\n\u001b[32m    500\u001b[39m     llm_config = llm_config.copy()\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\llm_config.py:84\u001b[39m, in \u001b[36mLLMConfig.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m         modified_kwargs[\u001b[33m\"\u001b[39m\u001b[33mconfig_list\u001b[39m\u001b[33m\"\u001b[39m] = [{**v, x: modified_kwargs[x]} \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m modified_kwargs[\u001b[33m\"\u001b[39m\u001b[33mconfig_list\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m     82\u001b[39m         modified_kwargs.pop(x)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28mself\u001b[39m._model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_base_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodified_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
                        "\u001b[31mValidationError\u001b[39m: 2 validation errors for _LLMConfig\nconfig_list.0.openai.model\n  Field required [type=missing, input_value={'client': <__main__.Open...>, 'api_type': 'openai'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nconfig_list.0.openai.client\n  Extra inputs are not permitted [type=extra_forbidden, input_value=<__main__.OpenAIChatCompl...t at 0x00000225D9CA7230>, input_type=OpenAIChatCompletionClient]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden"
                    ]
                }
            ],
            "source": [
                "planner = AssistantAgent(\n",
                "    name='planner',\n",
                "    llm_config={'client': qwen14_client, 'temperature': 0.3},\n",
                "    system_message=(\"You are a project planner. Break the user's request into a YAML list of atomic tasks. Stop when each sub-task can be executed in one short Python call or shell command inside the current Jupyter kernel.\"),\n",
                ")\n",
                "\n",
                "worker = AssistantAgent(\n",
                "    name='worker',\n",
                "    llm_config={'client': qwen32_client, 'temperature': 0},\n",
                "    system_message='Execute the given atomic task and return result.')\n",
                "worker.register_function(run_shell)\n",
                "\n",
                "coder = AssistantAgent(\n",
                "    name='coder',\n",
                "    llm_config={'client': devstral_client, 'temperature': 0},\n",
                "    system_message='You are a senior software engineer. Write, refactor, and debug code snippets as requested.')\n",
                "\n",
                "reviewer = AssistantAgent(\n",
                "    name='reviewer',\n",
                "    llm_config={'client': qwen14_client, 'temperature': 0},\n",
                "    system_message=(\"Evaluate the worker or coder output against the task description. If incorrect, respond with REVISE and instructions; otherwise APPROVED.\"),\n",
                ")\n",
                "\n",
                "agents = [planner, worker, coder, reviewer]\n",
                "group = GroupChat(agents=agents, max_round=30)\n",
                "proxy = UserProxyAgent(groupchat=group, human_input_mode='NEVER')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Driver function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_agent(prompt: str):\n",
                "    task_id = uuid.uuid4().hex[:8]\n",
                "    log_markdown(task_id, 'USER', prompt)\n",
                "    proxy.initiate_chat(prompt=prompt)\n",
                "    for m in group.chat_history:\n",
                "        log_markdown(task_id, m['role'], m['content'])\n",
                "    return LOG_DIR / f'{task_id}.md'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example call"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "run_agent('Generate Python code to scrape example.com daily and store results in SQLite …')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Git auto-commit"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git add agent_logs/*.md && (git diff --cached --quiet || git commit -m 'agent run') && git push"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Version info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip freeze | grep -E '(autogen|transformers|ollama)'"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
