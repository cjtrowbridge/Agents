{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Notebook\n",
    "This notebook demonstrates an agent workflow using autogen and models hosted on Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: ag2[openai] in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: autogen-ext[ollama] in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: jupytext in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.2)\n",
      "Requirement already satisfied: markdownify in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.46.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (4.9.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.0.8)\n",
      "Requirement already satisfied: diskcache in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (7.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from ag2[openai]) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (2.11.7)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (1.1.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.9.0)\n",
      "Requirement already satisfied: openai>=1.87.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (1.93.0)\n",
      "Requirement already satisfied: autogen-core==0.6.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.6.2)\n",
      "Requirement already satisfied: ollama>=0.4.7 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.5.1)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (0.55b1)\n",
      "Requirement already satisfied: pillow>=11.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (11.2.1)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (5.29.5)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (4.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (8.7.0)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (0.4.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (5.10.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (6.0.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.9 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (4.13.4)\n",
      "Requirement already satisfied: six<2,>=1.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (1.16.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2[openai]) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2[openai]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2[openai]) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=1.0->jupytext) (0.1.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.87.0->ag2[openai]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.87.0->ag2[openai]) (0.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken->ag2[openai]) (2024.11.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from docker->ag2[openai]) (310)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker->ag2[openai]) (2.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (4.24.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.25.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (3.23.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U autogen ag2[openai] autogen-ext[ollama] jupytext markdownify accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "# local fallback client if library missing or openai unavailable\n",
    "try:\n",
    "    from autogen import OpenAIChatCompletionClient as _OAIClient\n",
    "    import openai\n",
    "    OpenAIChatCompletionClient = _OAIClient\n",
    "except Exception:\n",
    "    class OpenAIChatCompletionClient:\n",
    "        def __init__(self, model, base_url=None, api_key=None):\n",
    "            self.model = model\n",
    "            self.base_url = base_url\n",
    "            self.api_key = api_key\n",
    "        def chat(self, messages, temperature=0):\n",
    "            raise NotImplementedError('OpenAIChatCompletionClient is unavailable')\n",
    "import pathlib, datetime, uuid, subprocess, shlex, markdownify\n",
    "\n",
    "REPO_ROOT = pathlib.Path.cwd()\n",
    "LOG_DIR = REPO_ROOT / 'agent_logs'\n",
    "LOG_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BASE_URL = 'http://docker-ai:11434/v1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen14_client = OpenAIChatCompletionClient(\n",
    "    model='Qwen2.5-14B-Instruct-1M-Q8_0:latest',\n",
    "    base_url=BASE_URL,\n",
    "    api_key='ollama')\n",
    "\n",
    "qwen32_client = OpenAIChatCompletionClient(\n",
    "    model='Qwen3-32B-Q5_0:latest',\n",
    "    base_url=BASE_URL,\n",
    "    api_key='ollama')\n",
    "\n",
    "devstral_client = OpenAIChatCompletionClient(\n",
    "    model='devstral:24b',\n",
    "    base_url=BASE_URL,\n",
    "    api_key='ollama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_markdown(task_id, role, content):\n",
    "    ts = datetime.datetime.utcnow().isoformat()\n",
    "    fn = LOG_DIR / f\"{task_id}.md\"\n",
    "    if not fn.exists():\n",
    "        with open(fn, 'w') as f:\n",
    "            f.write(f'---\\nid: {task_id}\\ncreated: {ts}\\n---\\n\\n')\n",
    "    with open(fn, 'a') as f:\n",
    "        f.write(f'### {ts} — {role}\\n\\n{markdownify.markdownify(content)}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_shell(cmd: str) -> str:\n",
    "    out = subprocess.check_output(shlex.split(cmd), text=True, timeout=900, stderr=subprocess.STDOUT)\n",
    "    return f'```shell\\n$ {cmd}\\n{out}\\n```'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = AssistantAgent(\n",
    "    name='planner',\n",
    "    llm_config={'config_list': [{ 'model': qwen14_client.model, 'base_url': qwen14_client.base_url, 'api_key': qwen14_client.api_key }], 'temperature': 0.3},\n",
    "    system_message=(\"You are a project planner. Break the user's request into a YAML list of atomic tasks. Stop when each sub-task can be executed in one short Python call or shell command inside the current Jupyter kernel.\"),\n",
    ")\n",
    "\n",
    "worker = AssistantAgent(\n",
    "    name='worker',\n",
    "    llm_config={'config_list': [{ 'model': qwen32_client.model, 'base_url': qwen32_client.base_url, 'api_key': qwen32_client.api_key }], 'temperature': 0},\n",
    "    system_message='Execute the given atomic task and return result.')\n",
    "worker.register_function({'run_shell': run_shell})\n",
    "\n",
    "coder = AssistantAgent(\n",
    "    name='coder',\n",
    "    llm_config={'config_list': [{ 'model': devstral_client.model, 'base_url': devstral_client.base_url, 'api_key': devstral_client.api_key }], 'temperature': 0},\n",
    "    system_message='You are a senior software engineer. Write, refactor, and debug code snippets as requested.')\n",
    "\n",
    "reviewer = AssistantAgent(\n",
    "    name='reviewer',\n",
    "    llm_config={'config_list': [{ 'model': qwen14_client.model, 'base_url': qwen14_client.base_url, 'api_key': qwen14_client.api_key }], 'temperature': 0},\n",
    "    system_message=(\"Evaluate the worker or coder output against the task description. If incorrect, respond with REVISE and instructions; otherwise APPROVED.\"),\n",
    ")\n",
    "\n",
    "agents = [planner, worker, coder, reviewer]\n",
    "group = GroupChat(agents=agents, max_round=30)\n",
    "manager = GroupChatManager(groupchat=group)\n",
    "proxy = UserProxyAgent(name='user', human_input_mode='NEVER', code_execution_config={'use_docker': False})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(prompt: str):\n",
    "    task_id = uuid.uuid4().hex[:8]\n",
    "    log_markdown(task_id, 'USER', prompt)\n",
    "    proxy.initiate_chat(manager, prompt=prompt)\n",
    "    for m in group.chat_history:\n",
    "        log_markdown(task_id, m['role'], m['content'])\n",
    "    return LOG_DIR / f'{task_id}.md'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_40000\\4122200196.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ts = datetime.datetime.utcnow().isoformat()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The group chat's internal speaker selection agent does not have an LLM configuration. Please provide a valid LLM config to the group chat's GroupChatManager or set it with the select_speaker_auto_llm_config parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGenerate Python code to scrape example.com daily and store results in SQLite …\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mrun_agent\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      2\u001b[39m task_id = uuid.uuid4().hex[:\u001b[32m8\u001b[39m]\n\u001b[32m      3\u001b[39m log_markdown(task_id, \u001b[33m'\u001b[39m\u001b[33mUSER\u001b[39m\u001b[33m'\u001b[39m, prompt)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mproxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m group.chat_history:\n\u001b[32m      6\u001b[39m     log_markdown(task_id, m[\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m], m[\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1487\u001b[39m, in \u001b[36mConversableAgent.initiate_chat\u001b[39m\u001b[34m(self, recipient, clear_history, silent, cache, max_turns, summary_method, summary_args, message, **kwargs)\u001b[39m\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1486\u001b[39m         msg2send = \u001b[38;5;28mself\u001b[39m.generate_init_message(message, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1487\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg2send\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1488\u001b[39m summary = \u001b[38;5;28mself\u001b[39m._summarize_chat(\n\u001b[32m   1489\u001b[39m     summary_method,\n\u001b[32m   1490\u001b[39m     summary_args,\n\u001b[32m   1491\u001b[39m     recipient,\n\u001b[32m   1492\u001b[39m     cache=cache,\n\u001b[32m   1493\u001b[39m )\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m, recipient]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1163\u001b[39m, in \u001b[36mConversableAgent.send\u001b[39m\u001b[34m(self, message, recipient, request_reply, silent)\u001b[39m\n\u001b[32m   1161\u001b[39m valid = \u001b[38;5;28mself\u001b[39m._append_oai_message(message, \u001b[33m\"\u001b[39m\u001b[33massistant\u001b[39m\u001b[33m\"\u001b[39m, recipient, is_sending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1162\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m     \u001b[43mrecipient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMessage can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1167\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:1271\u001b[39m, in \u001b[36mConversableAgent.receive\u001b[39m\u001b[34m(self, message, sender, request_reply, silent)\u001b[39m\n\u001b[32m   1269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m reply = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1273\u001b[39m     \u001b[38;5;28mself\u001b[39m.send(reply, sender, silent=silent)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:2836\u001b[39m, in \u001b[36mConversableAgent.generate_reply\u001b[39m\u001b[34m(self, messages, sender, **kwargs)\u001b[39m\n\u001b[32m   2834\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._match_trigger(reply_func_tuple[\u001b[33m\"\u001b[39m\u001b[33mtrigger\u001b[39m\u001b[33m\"\u001b[39m], sender):\n\u001b[32m-> \u001b[39m\u001b[32m2836\u001b[39m     final, reply = \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[43m=\u001b[49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfig\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m   2838\u001b[39m         log_event(\n\u001b[32m   2839\u001b[39m             \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2840\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreply_func_executed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2844\u001b[39m             reply=reply,\n\u001b[32m   2845\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:1225\u001b[39m, in \u001b[36mGroupChatManager.run_chat\u001b[39m\u001b[34m(self, messages, sender, config)\u001b[39m\n\u001b[32m   1222\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# select the next speaker\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m     speaker = \u001b[43mgroupchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[32m   1227\u001b[39m         iostream = IOStream.get_default()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:580\u001b[39m, in \u001b[36mGroupChat.select_speaker\u001b[39m\u001b[34m(self, last_speaker, selector)\u001b[39m\n\u001b[32m    577\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.next_agent(last_speaker)\n\u001b[32m    579\u001b[39m \u001b[38;5;66;03m# auto speaker selection with 2-agent chat\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_select_speaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_speaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:744\u001b[39m, in \u001b[36mGroupChat._auto_select_speaker\u001b[39m\u001b[34m(self, last_speaker, selector, messages, agents)\u001b[39m\n\u001b[32m    739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._validate_speaker_name(recipient, messages, sender, config, attempts_left, attempt, agents)\n\u001b[32m    741\u001b[39m \u001b[38;5;66;03m# Two-agent chat for speaker selection\u001b[39;00m\n\u001b[32m    742\u001b[39m \n\u001b[32m    743\u001b[39m \u001b[38;5;66;03m# Agent for checking the response from the speaker_select_agent\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m checking_agent, speaker_selection_agent = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_internal_agents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_attempts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_speaker_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;66;03m# Create the starting message\u001b[39;00m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.select_speaker_prompt_template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\autogen\\agentchat\\groupchat.py:671\u001b[39m, in \u001b[36mGroupChat._create_internal_agents\u001b[39m\u001b[34m(self, agents, max_attempts, messages, validate_speaker_name, selector)\u001b[39m\n\u001b[32m    668\u001b[39m speaker_selection_llm_config = \u001b[38;5;28mself\u001b[39m.select_speaker_auto_llm_config \u001b[38;5;129;01mor\u001b[39;00m selector.llm_config\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m speaker_selection_llm_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    672\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe group chat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms internal speaker selection agent does not have an LLM configuration. Please provide a valid LLM config to the group chat\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms GroupChatManager or set it with the select_speaker_auto_llm_config parameter.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    673\u001b[39m     )\n\u001b[32m    675\u001b[39m \u001b[38;5;66;03m# Agent for selecting a single agent name from the response\u001b[39;00m\n\u001b[32m    676\u001b[39m speaker_selection_agent = ConversableAgent(\n\u001b[32m    677\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mspeaker_selection_agent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    678\u001b[39m     system_message=\u001b[38;5;28mself\u001b[39m.select_speaker_msg(agents),\n\u001b[32m   (...)\u001b[39m\u001b[32m    682\u001b[39m     \u001b[38;5;66;03m# Suppresses some extra terminal outputs, outputs will be handled by select_speaker_auto_verbose\u001b[39;00m\n\u001b[32m    683\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: The group chat's internal speaker selection agent does not have an LLM configuration. Please provide a valid LLM config to the group chat's GroupChatManager or set it with the select_speaker_auto_llm_config parameter."
     ]
    }
   ],
   "source": [
    "run_agent('Generate Python code to scrape example.com daily and store results in SQLite …')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git auto-commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add agent_logs/*.md && (git diff --cached --quiet || git commit -m 'agent run') && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep -E '(autogen|transformers|ollama)'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
