{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agent Notebook\n",
        "This notebook demonstrates an agent workflow using autogen and models hosted on Ollama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autogen in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.5)\n",
            "Requirement already satisfied: ag2[openai] in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.9.5)\n",
            "Requirement already satisfied: autogen-ext[ollama] in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.2)\n",
            "Requirement already satisfied: jupytext in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.17.2)\n",
            "Requirement already satisfied: markdownify in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
            "Requirement already satisfied: accelerate in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.1)\n",
            "Requirement already satisfied: bitsandbytes in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.46.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (4.9.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.0.8)\n",
            "Requirement already satisfied: diskcache in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (5.6.3)\n",
            "Requirement already satisfied: docker in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (7.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.28.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from ag2[openai]) (25.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (1.1.1)\n",
            "Requirement already satisfied: termcolor in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (0.9.0)\n",
            "Requirement already satisfied: openai>=1.87.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ag2[openai]) (1.93.0)\n",
            "Requirement already satisfied: autogen-core==0.6.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.6.2)\n",
            "Requirement already satisfied: ollama>=0.4.7 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-ext[ollama]) (0.5.1)\n",
            "Requirement already satisfied: jsonref~=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.1.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.34.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (1.34.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (0.55b1)\n",
            "Requirement already satisfied: pillow>=11.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (11.2.1)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (5.29.5)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autogen-core==0.6.2->autogen-ext[ollama]) (4.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (8.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (0.4.2)\n",
            "Requirement already satisfied: nbformat in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (5.10.4)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupytext) (6.0.1)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.9 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (4.13.4)\n",
            "Requirement already satisfied: six<2,>=1.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdownify) (1.16.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.2.6)\n",
            "Requirement already satisfied: psutil in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (2.7.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.33.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->ag2[openai]) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4<5,>=4.9->markdownify) (2.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2[openai]) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.28.1->ag2[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2[openai]) (0.16.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.5.1)\n",
            "Requirement already satisfied: requests in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=1.0->jupytext) (0.1.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.87.0->ag2[openai]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.87.0->ag2[openai]) (0.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=2.6.1->ag2[openai]) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken->ag2[openai]) (2024.11.6)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: setuptools in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: pywin32>=304 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from docker->ag2[openai]) (310)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker->ag2[openai]) (2.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat->jupytext) (4.24.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from nbformat->jupytext) (5.14.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=2.6->nbformat->jupytext) (0.25.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->jupytext) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\cj\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\cj\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core==0.6.2->autogen-ext[ollama]) (3.23.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -U autogen ag2[openai] autogen-ext[ollama] jupytext markdownify accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
        "# local fallback client if library missing or openai unavailable\n",
        "try:\n",
        "    from autogen import OpenAIChatCompletionClient as _OAIClient\n",
        "    import openai\n",
        "    OpenAIChatCompletionClient = _OAIClient\n",
        "except Exception:\n",
        "    class OpenAIChatCompletionClient:\n",
        "        def __init__(self, model, base_url=None, api_key=None):\n",
        "            self.model = model\n",
        "            self.base_url = base_url\n",
        "            self.api_key = api_key\n",
        "        def chat(self, messages, temperature=0):\n",
        "            raise NotImplementedError('OpenAIChatCompletionClient is unavailable')\n",
        "import pathlib, datetime, uuid, subprocess, shlex, markdownify\n",
        "\n",
        "REPO_ROOT = pathlib.Path.cwd()\n",
        "LOG_DIR = REPO_ROOT / 'agent_logs'\n",
        "LOG_DIR.mkdir(exist_ok=True, parents=True)\n",
        "BASE_URL = 'http://docker-ai:11434/v1'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "qwen14_client = OpenAIChatCompletionClient(\n",
        "    model='Qwen2.5-14B-Instruct-1M-Q8_0:latest',\n",
        "    base_url=BASE_URL,\n",
        "    api_key='ollama')\n",
        "\n",
        "qwen32_client = OpenAIChatCompletionClient(\n",
        "    model='Qwen3-32B-Q5_0:latest',\n",
        "    base_url=BASE_URL,\n",
        "    api_key='ollama')\n",
        "\n",
        "devstral_client = OpenAIChatCompletionClient(\n",
        "    model='devstral:24b',\n",
        "    base_url=BASE_URL,\n",
        "    api_key='ollama')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Markdown logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_markdown(task_id, role, content):\n",
        "    ts = datetime.datetime.utcnow().isoformat()\n",
        "    fn = LOG_DIR / f\"{task_id}.md\"\n",
        "    if not fn.exists():\n",
        "        with open(fn, 'w') as f:\n",
        "            f.write(f'---\\nid: {task_id}\\ncreated: {ts}\\n---\\n\\n')\n",
        "    with open(fn, 'a') as f:\n",
        "        f.write(f'### {ts} — {role}\\n\\n{markdownify.markdownify(content)}\\n\\n')\n",
        "    print(f'[{ts}] {role}: {content}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shell helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_shell(cmd: str) -> str:\n",
        "    out = subprocess.check_output(shlex.split(cmd), text=True, timeout=900, stderr=subprocess.STDOUT)\n",
        "    return f'```shell\\n$ {cmd}\\n{out}\\n```'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent declarations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "planner = AssistantAgent(\n",
        "    name='planner',\n",
        "    llm_config={'config_list': [{ 'model': qwen14_client.model, 'base_url': qwen14_client.base_url, 'api_key': qwen14_client.api_key }], 'temperature': 0.3},\n",
        "    system_message=(\"You are a project planner. Break the user's request into a YAML list of atomic tasks. Stop when each sub-task can be executed in one short Python call or shell command inside the current Jupyter kernel.\"),\n",
        ")\n",
        "\n",
        "worker = AssistantAgent(\n",
        "    name='worker',\n",
        "    llm_config={'config_list': [{ 'model': qwen32_client.model, 'base_url': qwen32_client.base_url, 'api_key': qwen32_client.api_key }], 'temperature': 0},\n",
        "    system_message='Execute the given atomic task and return result.')\n",
        "worker.register_function({'run_shell': run_shell})\n",
        "\n",
        "coder = AssistantAgent(\n",
        "    name='coder',\n",
        "    llm_config={'config_list': [{ 'model': devstral_client.model, 'base_url': devstral_client.base_url, 'api_key': devstral_client.api_key }], 'temperature': 0},\n",
        "    system_message='You are a senior software engineer. Write, refactor, and debug code snippets as requested.')\n",
        "\n",
        "reviewer = AssistantAgent(\n",
        "    name='reviewer',\n",
        "    llm_config={'config_list': [{ 'model': qwen14_client.model, 'base_url': qwen14_client.base_url, 'api_key': qwen14_client.api_key }], 'temperature': 0},\n",
        "    system_message=(\"Evaluate the worker or coder output against the task description. If incorrect, respond with REVISE and instructions; otherwise APPROVED.\"),\n",
        ")\n",
        "\n",
        "agents = [planner, worker, coder, reviewer]\n",
        "group = GroupChat(agents=agents, max_round=30)\n",
        "manager = GroupChatManager(groupchat=group, llm_config={'config_list': [{ 'model': qwen14_client.model, 'base_url': qwen14_client.base_url, 'api_key': qwen14_client.api_key }], 'temperature': 0})\n",
        "proxy = UserProxyAgent(name='user', human_input_mode='NEVER', code_execution_config={'use_docker': False})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Driver function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_agent(prompt: str):\n",
        "    task_id = uuid.uuid4().hex[:8]\n",
        "    log_markdown(task_id, 'INFO', 'Agent run started')\n",
        "    log_markdown(task_id, 'USER', prompt)\n",
        "    proxy.initiate_chat(manager, message=prompt)\n",
        "    for m in group.chat_history:\n",
        "        log_markdown(task_id, m['role'], m['content'])\n",
        "    log_markdown(task_id, 'INFO', 'Agent run complete')\n",
        "    return LOG_DIR / f'{task_id}.md'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-07-07T03:03:12.216463] INFO: Agent run started\n",
            "[2025-07-07T03:03:12.217463] USER: Generate Python code to scrape example.com daily and store results in SQLite …\n",
            "\u001b[33muser\u001b[0m (to chat_manager):\n",
            "\n",
            "Generate Python code to scrape example.com daily and store results in SQLite …\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_40000\\1866636929.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.datetime.utcnow().isoformat()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[autogen.oai.client: 07-06 20:04:39] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "[autogen.oai.client: 07-06 20:04:39] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "[autogen.oai.client: 07-06 20:04:40] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "\u001b[32m\n",
            "Next speaker: planner\n",
            "\u001b[0m\n",
            "[autogen.oai.client: 07-06 20:05:43] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "\u001b[33mplanner\u001b[0m (to chat_manager):\n",
            "\n",
            "\n",
            "Generating Python code to scrape `example.com` daily and store the results in an SQLite database involves several steps. Below is a basic implementation using libraries like `requests`, `BeautifulSoup`, and `sqlite3`. This script will fetch data from `example.com`, parse it, and save it into an SQLite database.\n",
            "\n",
            "### Prerequisites\n",
            "1. **Python**: Ensure you have Python installed.\n",
            "2. **Libraries**:\n",
            "   - Install the required packages via pip if they are not already installed:\n",
            "     ```bash\n",
            "     pip install requests beautifulsoup4 sqlite3\n",
            "     ```\n",
            "\n",
            "### Code Implementation\n",
            "\n",
            "```python\n",
            "import os\n",
            "from datetime import date, timedelta\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "import sqlite3\n",
            "\n",
            "# Database setup\n",
            "DB_NAME = 'example_data.db'\n",
            "\n",
            "def initialize_db():\n",
            "    \"\"\"Initialize SQLite database and create a table if it doesn't exist.\"\"\"\n",
            "    conn = sqlite3.connect(DB_NAME)\n",
            "    cursor = conn.cursor()\n",
            "    \n",
            "    # Create table with id, date, and content columns\n",
            "    cursor.execute('''\n",
            "        CREATE TABLE IF NOT EXISTS scraped_data (\n",
            "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
            "            scrape_date DATE UNIQUE,\n",
            "            content TEXT\n",
            "        )\n",
            "    ''')\n",
            "    \n",
            "    conn.commit()\n",
            "    conn.close()\n",
            "\n",
            "def fetch_and_parse():\n",
            "    \"\"\"Fetch data from example.com and parse it.\"\"\"\n",
            "    url = 'http://example.com'\n",
            "    response = requests.get(url)\n",
            "    \n",
            "    if response.status_code == 200:\n",
            "        soup = BeautifulSoup(response.content, 'html.parser')\n",
            "        \n",
            "        # Extract the main content (this will vary based on actual structure of example.com)\n",
            "        content = soup.find('p').get_text(strip=True)  # Adjust this line as per your needs\n",
            "        \n",
            "        return content\n",
            "    else:\n",
            "        print(f\"Failed to fetch data: {response.status_code}\")\n",
            "        return None\n",
            "\n",
            "def store_in_db(content):\n",
            "    \"\"\"Store the fetched content in the SQLite database.\"\"\"\n",
            "    conn = sqlite3.connect(DB_NAME)\n",
            "    cursor = conn.cursor()\n",
            "    \n",
            "    today = date.today().isoformat()  # Get current date\n",
            "    \n",
            "    try:\n",
            "        cursor.execute('''\n",
            "            INSERT INTO scraped_data (scrape_date, content) VALUES (?, ?)\n",
            "        ''', (today, content))\n",
            "        \n",
            "        conn.commit()\n",
            "        print(f\"Data for {today} successfully stored.\")\n",
            "    \n",
            "    except sqlite3.IntegrityError as e:\n",
            "        print(\"Attempted to insert duplicate data:\", str(e))\n",
            "    \n",
            "    finally:\n",
            "        conn.close()\n",
            "\n",
            "def main():\n",
            "    initialize_db()  # Ensure the database is set up\n",
            "    \n",
            "    content = fetch_and_parse()\n",
            "    \n",
            "    if content:\n",
            "        store_in_db(content)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```\n",
            "\n",
            "### Explanation\n",
            "1. **Database Initialization**: The `initialize_db` function sets up an SQLite database with a table named `scraped_data`. This table stores the scraped date and content.\n",
            "2. **Fetching Data**: The `fetch_and_parse` function fetches data from `example.com`, parses it using BeautifulSoup, and extracts relevant information (in this case, just the text inside `<p>` tags).\n",
            "3. **Storing Data**: The `store_in_db` function inserts the fetched content into the SQLite database along with the current date.\n",
            "4. **Main Function**: The `main` function orchestrates the entire process by calling other functions in sequence.\n",
            "\n",
            "### Running Daily\n",
            "To run this script daily, you can set up a cron job (on Unix-like systems) or use Task Scheduler (Windows). Here’s how to do it using cron:\n",
            "\n",
            "1. Open your crontab file:\n",
            "   ```bash\n",
            "   crontab -e\n",
            "   ```\n",
            "2. Add the following line to schedule the script to run every day at midnight:\n",
            "   ```bash\n",
            "   0 0 * * * /usr/bin/python3 /path/to/your/script.py\n",
            "   ```\n",
            "\n",
            "### Notes\n",
            "- **Error Handling**: The code includes basic error handling for HTTP requests and database operations.\n",
            "- **Content Parsing**: Adjust the parsing logic in `fetch_and_parse` based on the actual HTML structure of `example.com`.\n",
            "- **Database Integrity**: Ensures that duplicate entries aren't inserted by checking for unique dates.\n",
            "\n",
            "This script provides a starting point, but you may need to adapt it further depending on specific requirements or changes in the target website's structure. Additionally, consider adding more robust error handling and logging mechanisms for production use. \n",
            "\n",
            "---\n",
            "\n",
            "Let me know if there’s anything else I can help with! 😊\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 07-06 20:05:46] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "[autogen.oai.client: 07-06 20:05:46] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "[autogen.oai.client: 07-06 20:05:46] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "\u001b[32m\n",
            "Next speaker: worker\n",
            "\u001b[0m\n",
            "[autogen.oai.client: 07-06 20:06:12] {708} WARNING - Model Qwen3-32B-Q5_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "\u001b[33mworker\u001b[0m (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.client: 07-06 20:06:32] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "[autogen.oai.client: 07-06 20:06:32] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "[autogen.oai.client: 07-06 20:06:32] {708} WARNING - Model Qwen2.5-14B-Instruct-1M-Q8_0:latest is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "\u001b[32m\n",
            "Next speaker: coder\n",
            "\u001b[0m\n",
            "[autogen.oai.client: 07-06 20:08:14] {708} WARNING - Model devstral:24b is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
            "\u001b[33mcoder\u001b[0m (to chat_manager):\n",
            "\n",
            "Sure, let's refactor and debug this code snippet step by step to ensure it works correctly.\n",
            "\n",
            "### Step-by-Step Refactoring and Debugging\n",
            "\n",
            "1. **Initialization of the Database**:\n",
            "   - Ensure that the database is initialized properly.\n",
            "   - Add error handling for database operations.\n",
            "\n",
            "2. **Fetching Data from `example.com`**:\n",
            "   - Use proper headers in requests to mimic a real browser visit.\n",
            "   - Handle potential exceptions during HTTP requests.\n",
            "\n",
            "3. **Parsing HTML Content**:\n",
            "   - Adjust parsing logic based on the actual structure of `example.com`.\n",
            "\n",
            "4. **Storing Data in SQLite Database**:\n",
            "   - Ensure data is stored correctly and handle any database integrity issues.\n",
            "\n",
            "5. **Main Function Execution**:\n",
            "   - Ensure that all functions are called in sequence properly.\n",
            "\n",
            "### Refactored Code\n",
            "\n",
            "```python\n",
            "import os\n",
            "from datetime import date, timedelta\n",
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "import sqlite3\n",
            "\n",
            "# Database setup\n",
            "DB_NAME = 'example_data.db'\n",
            "\n",
            "def initialize_db():\n",
            "    \"\"\"Initialize SQLite database and create a table if it doesn't exist.\"\"\"\n",
            "    try:\n",
            "        conn = sqlite3.connect(DB_NAME)\n",
            "        cursor = conn.cursor()\n",
            "\n",
            "        # Create table with id, date, and content columns\n",
            "        cursor.execute('''\n",
            "            CREATE TABLE IF NOT EXISTS scraped_data (\n",
            "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
            "                scrape_date DATE UNIQUE,\n",
            "                content TEXT\n",
            "            )\n",
            "        ''')\n",
            "\n",
            "        conn.commit()\n",
            "    except sqlite3.Error as e:\n",
            "        print(f\"Database error: {e}\")\n",
            "    finally:\n",
            "        if conn:\n",
            "            conn.close()\n",
            "\n",
            "def fetch_and_parse():\n",
            "    \"\"\"Fetch data from example.com and parse it.\"\"\"\n",
            "    url = 'http://example.com'\n",
            "    headers = {\n",
            "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
            "    }\n",
            "\n",
            "    try:\n",
            "        response = requests.get(url, headers=headers)\n",
            "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
            "\n",
            "        soup = BeautifulSoup(response.content, 'html.parser')\n",
            "\n",
            "        # Extract the main content (this will vary based on actual structure of example.com)\n",
            "        content = soup.find('p').get_text(strip=True)  # Adjust this line as per your needs\n",
            "\n",
            "        return content\n",
            "    except requests.RequestException as e:\n",
            "        print(f\"Request error: {e}\")\n",
            "        return None\n",
            "\n",
            "def store_in_db(content):\n",
            "    \"\"\"Store the fetched content in the SQLite database.\"\"\"\n",
            "    conn = sqlite3.connect(DB_NAME)\n",
            "    cursor = conn.cursor()\n",
            "\n",
            "    today = date.today().isoformat()  # Get current date\n",
            "\n",
            "    try:\n",
            "        cursor.execute('''\n",
            "            INSERT INTO scraped_data (scrape_date, content) VALUES (?, ?)\n",
            "        ''', (today, content))\n",
            "\n",
            "        conn.commit()\n",
            "        print(f\"Data for {today} successfully stored.\")\n",
            "    except sqlite3.IntegrityError as e:\n",
            "        print(\"Attempted to insert duplicate data:\", str(e))\n",
            "    finally:\n",
            "        if conn:\n",
            "            conn.close()\n",
            "\n",
            "def main():\n",
            "    initialize_db()  # Ensure the database is set up\n",
            "\n",
            "    content = fetch_and_parse()\n",
            "\n",
            "    if content:\n",
            "        store_in_db(content)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "```\n",
            "\n",
            "### Explanation of Changes\n",
            "1. **Database Initialization**:\n",
            "   - Added error handling for database operations.\n",
            "   - Ensured that the connection to the database is closed properly.\n",
            "\n",
            "2. **Fetching Data from `example.com`**:\n",
            "   - Added headers to mimic a real browser visit.\n",
            "   - Used `response.raise_for_status()` to handle HTTP errors gracefully.\n",
            "\n",
            "3. **Parsing HTML Content**:\n",
            "   - The parsing logic remains the same but can be adjusted based on the actual structure of `example.com`.\n",
            "\n",
            "4. **Storing Data in SQLite Database**:\n",
            "   - Ensured that the database connection is closed properly.\n",
            "   - Added error handling for duplicate entries.\n",
            "\n",
            "5. **Main Function Execution**:\n",
            "   - Ensured that all functions are called in sequence properly.\n",
            "\n",
            "### Running Daily\n",
            "To run this script daily, you can set up a cron job (on Unix-like systems) or use Task Scheduler (Windows). Here’s how to do it using cron:\n",
            "\n",
            "1. Open your crontab file:\n",
            "   ```bash\n",
            "   crontab -e\n",
            "   ```\n",
            "2. Add the following line to schedule the script to run every day at midnight:\n",
            "   ```bash\n",
            "   0 0 * * * /usr/bin/python3 /path/to/your/script.py\n",
            "   ```\n",
            "\n",
            "### Notes\n",
            "- **Error Handling**: The code includes basic error handling for HTTP requests and database operations.\n",
            "- **Content Parsing**: Adjust the parsing logic in `fetch_and_parse` based on the actual HTML structure of `example.com`.\n",
            "- **Database Integrity**: Ensures that duplicate entries aren't inserted by checking for unique dates.\n",
            "\n",
            "This script provides a starting point, but you may need to adapt it further depending on specific requirements or changes in the target website's structure. Additionally, consider adding more robust error handling and logging mechanisms for production use.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "run_agent('Generate Python code to scrape example.com daily and store results in SQLite …')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Git auto-commit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add agent_logs/*.md && (git diff --cached --quiet || git commit -m 'agent run') && git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Version info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip freeze | grep -E '(autogen|transformers|ollama)'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
